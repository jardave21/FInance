{"cells":[{"cell_type":"markdown","metadata":{"id":"v5hvo8QWN-a9"},"source":["#üó£Ô∏è **Whisper** - *Notebook creado por [DotCSV](https://www.youtube.com/channel/UCy5znSnfMsDwaLlROnZ7Qbg)*"]},{"cell_type":"markdown","source":["üö® Ten activada la **Aceleraci√≥n por hardware** con GPU en `\"Entorno de ejecuci√≥n\" > \"Cambiar tipo de entorno de ejecuci√≥n\"`"],"metadata":{"id":"f-BcD0b8hwdA"}},{"cell_type":"code","source":["#@title ‚öôÔ∏è Ejecutar esta celda para instalar las librer√≠a.\n","\"\"\"\n","To write this piece of code I took inspiration/code from a lot of places.\n","It was late night, so I'm not sure how much I created or just copied o.O\n","Here are some of the possible references:\n","https://blog.addpipe.com/recording-audio-in-the-browser-using-pure-html5-and-minimal-javascript/\n","https://stackoverflow.com/a/18650249\n","https://hacks.mozilla.org/2014/06/easy-audio-capture-with-the-mediarecorder-api/\n","https://air.ghost.io/recording-to-an-audio-file-using-html5-and-js/\n","https://stackoverflow.com/a/49019356\n","\"\"\"\n","\n","!pip install git+https://github.com/openai/whisper.git\n","!pip install jiwer\n","\n","from IPython.display import HTML, Audio\n","from google.colab.output import eval_js\n","from base64 import b64decode\n","import numpy as np\n","from scipy.io.wavfile import read as wav_read\n","import io\n","import ffmpeg\n","\n","AUDIO_HTML = \"\"\"\n","<script>\n","var my_div = document.createElement(\"DIV\");\n","var my_p = document.createElement(\"P\");\n","var my_btn = document.createElement(\"BUTTON\");\n","var t = document.createTextNode(\"Press to start recording\");\n","\n","my_btn.appendChild(t);\n","//my_p.appendChild(my_btn);\n","my_div.appendChild(my_btn);\n","document.body.appendChild(my_div);\n","\n","var base64data = 0;\n","var reader;\n","var recorder, gumStream;\n","var recordButton = my_btn;\n","\n","var handleSuccess = function(stream) {\n","  gumStream = stream;\n","  var options = {\n","    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n","    mimeType : 'audio/webm;codecs=opus'\n","    //mimeType : 'audio/webm;codecs=pcm'\n","  };            \n","  //recorder = new MediaRecorder(stream, options);\n","  recorder = new MediaRecorder(stream);\n","  recorder.ondataavailable = function(e) {            \n","    var url = URL.createObjectURL(e.data);\n","    var preview = document.createElement('audio');\n","    preview.controls = true;\n","    preview.src = url;\n","    document.body.appendChild(preview);\n","\n","    reader = new FileReader();\n","    reader.readAsDataURL(e.data); \n","    reader.onloadend = function() {\n","      base64data = reader.result;\n","      //console.log(\"Inside FileReader:\" + base64data);\n","    }\n","  };\n","  recorder.start();\n","  };\n","\n","recordButton.innerText = \"Recording... press to stop\";\n","\n","navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n","\n","\n","function toggleRecording() {\n","  if (recorder && recorder.state == \"recording\") {\n","      recorder.stop();\n","      gumStream.getAudioTracks()[0].stop();\n","      recordButton.innerText = \"Saving the recording... pls wait!\"\n","  }\n","}\n","\n","// https://stackoverflow.com/a/951057\n","function sleep(ms) {\n","  return new Promise(resolve => setTimeout(resolve, ms));\n","}\n","\n","var data = new Promise(resolve=>{\n","//recordButton.addEventListener(\"click\", toggleRecording);\n","recordButton.onclick = ()=>{\n","toggleRecording()\n","\n","sleep(2000).then(() => {\n","  // wait 2000ms for the data to be available...\n","  // ideally this should use something like await...\n","  //console.log(\"Inside data:\" + base64data)\n","  resolve(base64data.toString())\n","\n","});\n","\n","}\n","});\n","      \n","</script>\n","\"\"\"\n","\n","def get_audio():\n","  display(HTML(AUDIO_HTML))\n","  data = eval_js(\"data\")\n","  binary = b64decode(data.split(',')[1])\n","  \n","  process = (ffmpeg\n","    .input('pipe:0')\n","    .output('pipe:1', format='wav')\n","    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n","  )\n","  output, err = process.communicate(input=binary)\n","  \n","  riff_chunk_size = len(output) - 8\n","  # Break up the chunk size into four bytes, held in b.\n","  q = riff_chunk_size\n","  b = []\n","  for i in range(4):\n","      q, r = divmod(q, 256)\n","      b.append(r)\n","\n","  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n","  riff = output[:4] + bytes(b) + output[8:]\n","\n","  sr, audio = wav_read(io.BytesIO(riff))\n","\n","  return audio, sr"],"metadata":{"cellView":"form","id":"SJl7HJOeo0-P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675270868366,"user_tz":360,"elapsed":10259,"user":{"displayName":"Jard_ave","userId":"01873399045357920461"}},"outputId":"588e2bca-4fce-4a8f-85f1-41ca49abfadc"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/openai/whisper.git\n","  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-iy9ca4ih\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-iy9ca4ih\n","  Resolved https://github.com/openai/whisper.git to commit 5c1a8c10e762bf9c29fcf6b3e40f17bc8ab09864\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (1.21.6)\n","Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (1.13.1+cu116)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (4.64.1)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (9.0.0)\n","Requirement already satisfied: transformers>=4.19.0 in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (4.26.0)\n","Requirement already satisfied: ffmpeg-python==0.2.0 in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (0.2.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from ffmpeg-python==0.2.0->openai-whisper==20230124) (0.16.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (2022.6.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (21.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (0.12.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (0.13.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (3.9.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (2.25.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->openai-whisper==20230124) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers>=4.19.0->openai-whisper==20230124) (3.0.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (1.24.3)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: jiwer in /usr/local/lib/python3.8/dist-packages (2.5.1)\n","Requirement already satisfied: levenshtein==0.20.2 in /usr/local/lib/python3.8/dist-packages (from jiwer) (0.20.2)\n","Requirement already satisfied: rapidfuzz<3.0.0,>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from levenshtein==0.20.2->jiwer) (2.13.7)\n"]}]},{"cell_type":"markdown","metadata":{"id":"-9_I0W3tqTjr"},"source":["## üéôÔ∏è **Grabar y transcribir** [Elige la tarea]"]},{"cell_type":"code","source":["Tarea = \"Transcript to Language\" #@param [\"Transcript to Language\", \"Translate to English\"]\n","import numpy as np\n","import whisper\n","from scipy.io.wavfile import write\n","from IPython.display import clear_output\n","\n","task = \"translate\" if Tarea == \"Translate to English\" else \"transcribe\" \n","\n","audio, sr = get_audio()\n","write('bolsa_de_valores.wav', sr, audio)\n","\n","!whisper \"bolsa_de_valores.wav\" --task {task} --model medium --verbose False\n","\n","clear_output()\n","if task == \"translate\":\n","  print(\"-- TRADUCCI√ìN A INGL√âS --\\n\")\n","else:\n","  print(\"-- TRANSCRIPCI√ìN A ESPA√ëOL --\\n\")\n","  \n","print(open('bolsa_de_valores.wav.txt').read())"],"metadata":{"id":"opNkn_Lgpat4","colab":{"base_uri":"https://localhost:8080/","height":95},"outputId":"ad0ba702-dd13-485c-ba16-0e66529334d6"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<script>\n","var my_div = document.createElement(\"DIV\");\n","var my_p = document.createElement(\"P\");\n","var my_btn = document.createElement(\"BUTTON\");\n","var t = document.createTextNode(\"Press to start recording\");\n","\n","my_btn.appendChild(t);\n","//my_p.appendChild(my_btn);\n","my_div.appendChild(my_btn);\n","document.body.appendChild(my_div);\n","\n","var base64data = 0;\n","var reader;\n","var recorder, gumStream;\n","var recordButton = my_btn;\n","\n","var handleSuccess = function(stream) {\n","  gumStream = stream;\n","  var options = {\n","    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n","    mimeType : 'audio/webm;codecs=opus'\n","    //mimeType : 'audio/webm;codecs=pcm'\n","  };            \n","  //recorder = new MediaRecorder(stream, options);\n","  recorder = new MediaRecorder(stream);\n","  recorder.ondataavailable = function(e) {            \n","    var url = URL.createObjectURL(e.data);\n","    var preview = document.createElement('audio');\n","    preview.controls = true;\n","    preview.src = url;\n","    document.body.appendChild(preview);\n","\n","    reader = new FileReader();\n","    reader.readAsDataURL(e.data); \n","    reader.onloadend = function() {\n","      base64data = reader.result;\n","      //console.log(\"Inside FileReader:\" + base64data);\n","    }\n","  };\n","  recorder.start();\n","  };\n","\n","recordButton.innerText = \"Recording... press to stop\";\n","\n","navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n","\n","\n","function toggleRecording() {\n","  if (recorder && recorder.state == \"recording\") {\n","      recorder.stop();\n","      gumStream.getAudioTracks()[0].stop();\n","      recordButton.innerText = \"Saving the recording... pls wait!\"\n","  }\n","}\n","\n","// https://stackoverflow.com/a/951057\n","function sleep(ms) {\n","  return new Promise(resolve => setTimeout(resolve, ms));\n","}\n","\n","var data = new Promise(resolve=>{\n","//recordButton.addEventListener(\"click\", toggleRecording);\n","recordButton.onclick = ()=>{\n","toggleRecording()\n","\n","sleep(2000).then(() => {\n","  // wait 2000ms for the data to be available...\n","  // ideally this should use something like await...\n","  //console.log(\"Inside data:\" + base64data)\n","  resolve(base64data.toString())\n","\n","});\n","\n","}\n","});\n","      \n","</script>\n"]},"metadata":{}}]},{"cell_type":"markdown","source":["## üëâ  S√≥lo **transcribir** audio al idioma original. (X ‚ñ∫ X)"],"metadata":{"id":"XXZooJ-Wy9EL"}},{"cell_type":"code","source":["!whisper \"/content/38983397.wav\" --language English --task transcribe --model medium --verbose False --output_dir audio_transcription"],"metadata":{"id":"Aejy9Haxy81U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675271227064,"user_tz":360,"elapsed":351078,"user":{"displayName":"Jard_ave","userId":"01873399045357920461"}},"outputId":"9ec426ff-afe4-4dc3-85d4-41ed57605f80"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.42G/1.42G [00:05<00:00, 260MiB/s]\n","tcmalloc: large alloc 1528012800 bytes == 0xb750000 @  0x7f8f43596680 0x7f8f435b7824 0x5f97c1 0x649901 0x5c43c6 0x4f327e 0x64e618 0x505163 0x56bbe1 0x5f5ee6 0x56bab6 0x569d8a 0x5f60c3 0x56cc92 0x5f5ee6 0x56bab6 0x569d8a 0x68e267 0x67d9b1 0x67da2f 0x67dad1 0x67fbf7 0x6b8082 0x6b840d 0x7f8f43395083 0x5faa2e\n","100% 123816/123816 [05:12<00:00, 395.97frames/s]\n"]}]},{"cell_type":"markdown","source":["## üëâ  S√≥lo **traducir** audio del idioma original al ingl√©s. (X ‚ñ∫ English)"],"metadata":{"id":"wOdSeKWnzJSV"}},{"cell_type":"code","source":["!whisper \"/content/audio.mp3\" --task translate --model medium"],"metadata":{"id":"UlVRSbPC7IRJ"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1CvvYPAFemIZdSOt9fhN541esSlZR7Ic6","timestamp":1668651599219},{"file_id":"1lXtPVNqMy-lg1QrGOG9qZ96rOXNMnNrh","timestamp":1668360149938},{"file_id":"https://github.com/openai/whisper/blob/master/notebooks/LibriSpeech.ipynb","timestamp":1667820298272}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.9"}},"nbformat":4,"nbformat_minor":0}